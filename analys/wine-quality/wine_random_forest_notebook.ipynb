{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e868d603",
   "metadata": {},
   "source": [
    "# Wine Classification with RandomForest — Step by Step\n",
    "\n",
    "This notebook walks you through a complete **multiclass classification** workflow using scikit-learn's built-in **Wine** dataset and a **RandomForestClassifier**.\n",
    "\n",
    "**What you'll do:**\n",
    "1. Install and import dependencies\n",
    "2. Load and inspect the dataset\n",
    "3. Split data into train/test sets\n",
    "4. Train a RandomForest model\n",
    "5. Evaluate accuracy and inspect predictions\n",
    "6. Visualize the confusion matrix\n",
    "7. Print a classification report\n",
    "8. Analyze feature importances\n",
    "9. Run 5-fold cross-validation\n",
    "10. Plot ROC curves (one-vs-rest) with AUC for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c2116",
   "metadata": {},
   "source": [
    "## Step 0 — (Optional) Install dependencies\n",
    "\n",
    "Run this cell **only if** you don't have the required packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e5b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, uncomment and run:\n",
    "# !pip install scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e9a6da",
   "metadata": {},
   "source": [
    "## Step 1 — Import libraries\n",
    "\n",
    "We import NumPy for numerical operations, Matplotlib for plotting, and scikit-learn for data loading, modeling, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5abc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64738c8",
   "metadata": {},
   "source": [
    "## Step 2 — Load and inspect the dataset\n",
    "\n",
    "We use scikit-learn's `load_wine()` to get features `X`, labels `y`, and metadata like feature and target names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = load_wine()\n",
    "X = wine_data.data\n",
    "y = wine_data.target\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Number of classes: {len(wine_data.target_names)}\")\n",
    "print(\"Classes:\", wine_data.target_names)\n",
    "print(\"First 5 feature names:\", wine_data.feature_names[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9761446",
   "metadata": {},
   "source": [
    "## Step 3 — Train/Test split\n",
    "\n",
    "We split the dataset into training and test sets so we can evaluate the model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "print(f\"Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1935260b",
   "metadata": {},
   "source": [
    "## Step 4 — Initialize and train the RandomForest\n",
    "\n",
    "We create a `RandomForestClassifier` with a fixed random seed for reproducibility and fit it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39509de3",
   "metadata": {},
   "source": [
    "## Step 5 — Make predictions and compute accuracy\n",
    "\n",
    "We predict on the test set and measure **accuracy** (fraction of correct predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000eb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a569cced",
   "metadata": {},
   "source": [
    "## Step 6 — Confusion matrix (numeric and heatmap)\n",
    "\n",
    "The confusion matrix shows how often predictions match the true labels per class.\n",
    "We print the raw matrix and then visualize it as a heatmap using **Matplotlib**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f62180",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix (numeric):\\n\", conf_matrix)\n",
    "\n",
    "# Plot confusion matrix with Matplotlib (no seaborn)\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(conf_matrix, interpolation='nearest')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "tick_marks = np.arange(len(wine_data.target_names))\n",
    "plt.xticks(tick_marks, wine_data.target_names, rotation=45, ha='right')\n",
    "plt.yticks(tick_marks, wine_data.target_names)\n",
    "\n",
    "# Add counts to each cell\n",
    "thresh = conf_matrix.max() / 2.0 if conf_matrix.max() > 0 else 0.5\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, format(conf_matrix[i, j], 'd'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248294e6",
   "metadata": {},
   "source": [
    "## Step 7 — Classification report\n",
    "\n",
    "The classification report provides **precision**, **recall**, and **F1-score** for each class, along with macro/micro averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=wine_data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c632e49",
   "metadata": {},
   "source": [
    "## Step 8 — Feature importances\n",
    "\n",
    "Random forests provide an estimate of **feature importance**. We display the importance values and plot them as a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for i in range(X.shape[1]):\n",
    "    print(f\"{wine_data.feature_names[indices[i]]}: {feature_importances[indices[i]]:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(X.shape[1]), feature_importances[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), [wine_data.feature_names[i] for i in indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b154bdd",
   "metadata": {},
   "source": [
    "## Step 9 — 5-fold cross-validation\n",
    "\n",
    "We evaluate the model with **5-fold cross-validation** on the full dataset to assess stability across different splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation accuracy: {cross_val.mean():.2f} ± {cross_val.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f87106",
   "metadata": {},
   "source": [
    "## Step 10 — ROC curves and AUC (one-vs-rest)\n",
    "\n",
    "For multiclass problems, we compute **one-vs-rest** ROC curves: for each class, treat it as positive vs. all others as negative.\n",
    "We use predicted probabilities from the RandomForest to compute **AUC** per class and plot the ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities for test set\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "# Compute ROC and AUC per class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "n_classes = len(wine_data.target_names)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test == i, y_prob[:, i])\n",
    "    roc_auc[i] = roc_auc_score(y_test == i, y_prob[:, i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"Class {wine_data.target_names[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves — Wine Classification (One-vs-Rest)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d13a8",
   "metadata": {},
   "source": [
    "## 📘 What each code block does\n",
    "\n",
    "**Step 0 — Install dependencies (optional)**  \n",
    "- Provides a `pip install` command (commented out) in case required libraries are missing.\n",
    "\n",
    "**Step 1 — Import libraries**  \n",
    "- Imports NumPy for numeric operations and Matplotlib for plotting.  \n",
    "- Imports scikit-learn utilities: dataset loader, model selection helpers, the RandomForest model, and metrics for evaluation.\n",
    "\n",
    "**Step 2 — Load and inspect the dataset**  \n",
    "- Loads the Wine dataset into `X` (features) and `y` (labels).  \n",
    "- Prints dataset shape, class names, and some feature names to quickly verify what we’re working with.\n",
    "\n",
    "**Step 3 — Train/Test split**  \n",
    "- Splits the data into a training set (70%) and a test set (30%).  \n",
    "- `random_state=42` ensures reproducibility of the split.\n",
    "\n",
    "**Step 4 — Initialize and train the RandomForest**  \n",
    "- Creates a `RandomForestClassifier` with 100 trees.  \n",
    "- Fits the model on the training data (`X_train`, `y_train`).\n",
    "\n",
    "**Step 5 — Make predictions and compute accuracy**  \n",
    "- Uses the trained model to predict `y_pred` on `X_test`.  \n",
    "- Computes overall **accuracy** — the share of correct predictions.\n",
    "\n",
    "**Step 6 — Confusion matrix (numeric and heatmap)**  \n",
    "- Computes a confusion matrix to see per-class correctness and error types.  \n",
    "- Plots the matrix using Matplotlib and annotates each cell with counts.\n",
    "\n",
    "**Step 7 — Classification report**  \n",
    "- Prints **precision**, **recall**, **F1-score**, and **support** for each class, plus macro/weighted averages.\n",
    "\n",
    "**Step 8 — Feature importances**  \n",
    "- Extracts `model.feature_importances_` to see which features the RandomForest considered most informative.  \n",
    "- Sorts and displays the list, then plots a bar chart of importances.\n",
    "\n",
    "**Step 9 — 5-fold cross-validation**  \n",
    "- Evaluates the model using 5-fold CV over the **entire dataset** (train/test splits vary inside CV).  \n",
    "- Reports mean accuracy and its standard deviation as a robustness check.\n",
    "\n",
    "**Step 10 — ROC curves and AUC (one-vs-rest)**  \n",
    "- Gets class probability estimates with `predict_proba`.  \n",
    "- For each class, computes an ROC curve by treating that class as positive vs. the others as negative.  \n",
    "- Plots ROC curves and shows **AUC** per class (area under the curve)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08318d14",
   "metadata": {},
   "source": [
    "## ✅ Results & Interpretation (from your run)\n",
    "\n",
    "**Overall accuracy:** `1.00`  \n",
    "The model predicted **all 54 test samples correctly**.\n",
    "\n",
    "**Confusion Matrix (perfect classification):**\n",
    "```\n",
    "[[19  0  0]\n",
    " [ 0 21  0]\n",
    " [ 0  0 14]]\n",
    "```\n",
    "- Every class (0, 1, 2) is predicted without any mistakes.\n",
    "\n",
    "**Classification Report (all 1.00):**\n",
    "- Precision, Recall, F1-score are **1.00 for each class** and overall.\n",
    "\n",
    "**Feature Importances (top features):**\n",
    "- `color_intensity`: 0.1802  \n",
    "- `flavanoids`: 0.1659  \n",
    "- `alcohol`: 0.1420  \n",
    "- `proline`: 0.1261  \n",
    "- (`od280/od315_of_diluted_wines`, `hue`, `total_phenols` follow)  \n",
    "\n",
    "**5-fold Cross-Validation:** `0.97 ± 0.02`  \n",
    "- Indicates **strong generalization** across different splits.\n",
    "\n",
    "**ROC / AUC:**  \n",
    "- AUC = **1.00 for each class** → ROC curves hug the top-left corner.\n",
    "\n",
    "### Visuals from your run\n",
    "(If you ran and saved screenshots, you can view them below.)  \n",
    "<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Lucas-Peterson/my-analysis/main/analys/wine-quality/Confusion_Matrix.png\" width=\"520\" alt=\"Confusion Matrix\" />  \n",
    "<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Lucas-Peterson/my-analysis/main/analys/wine-quality/feature_importances.png\" width=\"720\" alt=\"Feature Importances\" />  \n",
    "<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Lucas-Peterson/my-analysis/main/analys/wine-quality/ROC_Curves_for_Wine_Classification.png\" width=\"720\" alt=\"ROC Curves\" />  \n",
    "\n",
    "### Takeaways\n",
    "- The **Wine** dataset is well-separated; RandomForest can achieve **perfect** test accuracy on some splits.  \n",
    "- Cross-validation at ~**97%** confirms it's not just luck on one split.  \n",
    "- Most discriminative features here are **color intensity**, **flavanoids**, **alcohol**, and **proline**.  \n",
    "- For comparison or classroom use, try also **LogisticRegression** and **SVM** to see performance vs. model complexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
